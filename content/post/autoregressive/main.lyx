#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Section -> #
\end_layout

\begin_layout Plain Layout
Subsection -> ## and so on
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Autoregressive models use their output to arrive at predictions.
 In machine learning, this amounts to 
\begin_inset Quotes eld
\end_inset

training on the output
\begin_inset Quotes erd
\end_inset

, i.e., generated data.
 More broadly, intelligent behavior is often accompanied by deep thought
 or even dreaming between actions.
 In both of these cases, the system is decoupled from the ground truth.
 Despite this apparent conundrum, there seems to be a benefit.
\end_layout

\begin_layout Standard
Or is there? 
\begin_inset CommandInset href
LatexCommand href
name "The data processing inequality"
target "https://en.wikipedia.org/wiki/Data_processing_inequality"
literal "false"

\end_inset

 asserts that no procedure, however deep, can arrive increase information.
 How can this be reconciled?
\end_layout

\begin_layout Subsection
The data-processing inequality
\end_layout

\begin_layout Standard
The data-processing inequality posits that for any processing procedure
 
\begin_inset Formula $\hat{X}=f(X)$
\end_inset

, the information that the ground truth data 
\begin_inset Formula $X$
\end_inset

 contains about the source 
\begin_inset Formula $X^{\ast}$
\end_inset

 cannot increase, 
\begin_inset Formula 
\[
\mathbb{I}\left[\hat{X}=f(X);X^{\ast}\right]\leq\mathbb{I}\left[X^{\ast};X\right]\quad\forall\,f.
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Bayesian inference
\end_layout

\begin_layout Standard
We can now extend this notion towards making 
\begin_inset Formula $f$
\end_inset

 probabilistic: Namely, let's consider a ground truth distribution that
 we want to model, 
\begin_inset Formula $Y\sim p^{\ast}$
\end_inset

.
 Ideally, the model 
\begin_inset Formula $\hat{X}\sim\hat{p}$
\end_inset

 should be as close as possible to 
\begin_inset Formula $p^{\ast}$
\end_inset

, that is the 
\begin_inset Quotes eld
\end_inset

loss
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $\mathbb{I}\left[\hat{p};p^{\ast}\right]$
\end_inset

 should be minimized.
 However, there is only a finite amount of samples 
\begin_inset Formula $X$
\end_inset

 from 
\begin_inset Formula $p^{\ast}$
\end_inset

 available to fit 
\begin_inset Formula $\hat{p}.$
\end_inset

 The data processing inequality now boils down to whether we can find a
 sampling sequence
\begin_inset Formula 
\[
X\rightarrow\hat{p}^{(1)}\sim\hat{X}^{(1)}\rightarrow\hat{p}^{(2)}\sim\hat{X}^{(2)}\rightarrow\ldots\rightarrow\hat{p}^{(n)}\sim\hat{X}^{(n)}
\]

\end_inset


\end_layout

\begin_layout Standard
with the arrows denote ways to translate samples 
\begin_inset Formula $X$
\end_inset

 to (probabilistic) models 
\begin_inset Formula $\hat{p}$
\end_inset

.
 Is it possible to achieve 
\begin_inset Formula $\mathbb{I}\left[X;X^{(n)}\right]\geq\mathbb{I}\left[X;X^{(1)}\right]$
\end_inset

?
\end_layout

\begin_layout Standard
In fact, we can prove that such a procedure can't yield an improvement on
 average.
 Suppose we constrain our model class 
\begin_inset Formula $\hat{p}$
\end_inset

 towards a posterior 
\begin_inset Formula $\hat{p}(x|X)$
\end_inset

.
 Now, if we sample from this model, it turns out that we on average do not
 gain anything over the previous model by incorporating generated data 
\begin_inset Formula $\hat{X}$
\end_inset

, i.e.,
\begin_inset Formula 
\[
\langle\hat{p}(x|\hat{X},X)\rangle_{\hat{X}\sim\hat{p}(x|X)}=\hat{p}(x|X).
\]

\end_inset


\end_layout

\begin_layout Standard
The proof is a straightforward application of Bayes' theorem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\langle\hat{p}(x|\hat{X}X)\rangle_{\hat{X}\sim\hat{p}(\hat{X}|X)} & =\int_{\hat{X}}\frac{\hat{p}(y,\hat{X}|X)\cancel{\hat{p}(\hat{X}|X)}}{\cancel{\hat{p}(\hat{X}|X)}}\\
 & =\hat{p}(x|X).
\end{align*}

\end_inset

 
\end_layout

\begin_layout Subsection
Can we safely stop thinking?
\end_layout

\begin_layout Standard
Imagination, hallucination, and dreaming are all autoregressive in this
 sense: Decoupled from a finite data sample, the brain ponders what it remembers
, hopefully arriving at a better model.
 Even more clearly, closing your eyes and giving things a good thought can
 definitely improve your actions.
 So can it really be in vain?
\end_layout

\begin_layout Standard
So far, we have adopted a puristic Bayesian inference view.
 However, in practice information needs not only to be present, but 
\emph on
be made accesible
\emph default
.
 In practice, this is key and is the reason why we need brains or computers
 at all to make sense of the world despite the information processing equality.
 
\end_layout

\begin_layout Standard
The intuitive idea is that sampling from even a premature model will help
 with exploration: Maybe you'll get an idea that helps you downstream.
 While easy to write, it is in general very hard to calculate the above
 posterior 
\begin_inset Formula $\hat{p}(x|X)$
\end_inset

, as it involved to an optimization over an infitely large function space.
 Bootstrapping the model with its own samples may help: Sampling a premature
 model 
\begin_inset Formula $\hat{X}\sim\hat{p}^{(1)}(x|X)$
\end_inset

 can for example be seen as introducing noise.
 This can have similar benefits to stochastic gradient descent, helping
 exploration towards a better global minimum â€“ a better world model.
 
\end_layout

\end_body
\end_document
