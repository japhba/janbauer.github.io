#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
In statistical physics, we are often dealing with systems that comprise
 many components.
 In order to calculate their statistics, high-dimensional integrals over
 those variables 
\begin_inset Formula $\bm{x}\in\mathbb{R}^{N}$
\end_inset

 with 
\begin_inset Formula $N\gg1$
\end_inset

 are required.
 A typical form is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathcal{Z}=\int_{\bm{x}}e^{S_{\text{0}}(\bm{x})+S_{V}(\bm{x})},
\]

\end_inset


\end_layout

\begin_layout Standard
where I introduced 
\begin_inset Formula $\int_{x}:=\int_{-\infty}^{\infty}dx$
\end_inset

 for brevity.
\end_layout

\begin_layout Standard
In general, 
\begin_inset Formula $S_{V}(\bm{x})$
\end_inset

 couples variables in such a way that the integration does not factorize.
 In 1D, such integrals would be tractable by numerical methods still, so
 there no real problem exists.
 This ceases to be the case in higher dimensions, where the Curse of Dimensional
ity manifests.
 Luckily, there is a plethora of approximation methods for this case.
 Mean-field theory is a particular example for this, which will be the subject
 of this post.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
To illustrate how DMFT can be of help here, let's first consider a toy problem,
 with
\begin_inset Formula 
\begin{align*}
S_{0}(\bm{x}) & =-\bm{x}^{T}\bm{x}\\
S_{V}(\bm{x}) & =\left(A\bm{x}\right)^{T}\left(A\bm{x}\right)\\
 & =A_{ij}A_{ik}x_{i}x_{k},
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $A_{ij}=1$
\end_inset

 for simplicity.
 This introduces an interdependence between variables that prevents factorizatio
n.
 
\end_layout

\begin_layout Subsection*
Decoupling
\end_layout

\begin_layout Standard
To mitigate this, DMFT introduces an 
\series bold
auxiliary field
\series default
 that caps the threads between 
\begin_inset Formula $\bm{x}$
\end_inset

 and 
\begin_inset Formula $A\bm{x}$
\end_inset

.
 To accomplish this, we use the mathemagical identity
\begin_inset Formula 
\[
\delta\left(\bm{y}-\bm{x}\right)=\int_{\tilde{\bm{y}}}\,\exp\left(-i\tilde{\bm{y}}^{T}\left(\bm{y}-\bm{x}\right)\right).
\]

\end_inset


\end_layout

\begin_layout Standard
Further down in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Lagrange-multipliers-delta-gauss"
plural "false"
caps "false"
noprefix "false"

\end_inset

, I will attempt a more intuitive picture for the identity.
 
\end_layout

\begin_layout Standard
With this we can rewrite
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
 & \int_{\bm{x}\bm{y}}\:e^{S_{0}(\bm{x})+\bm{y}^{T}\bm{y}}\,\delta\left(\bm{y}-A\bm{x}\right)\\
= & \int_{\bm{x}\bm{y}\tilde{\bm{y}}}e^{S_{0}(\bm{x})+\bm{y}^{T}\bm{y}-i\tilde{\bm{y}}^{T}\left(\bm{y}-A\bm{x}\right)}\,\\
 & \text{isolate the "microscopic" variable }\text{\ensuremath{\bm{x}}}\\
= & \int_{\bm{y}\tilde{\bm{y}}}\:e^{-i\tilde{\bm{y}}^{T}\bm{y}+\bm{y}^{T}\bm{y}}\:\int_{\bm{x}}\:e^{S_{0}(\bm{x})+i\tilde{\bm{y}}^{T}A\bm{x}}\\
 & \text{use that now, \ensuremath{\bm{x}} decouples, and \ensuremath{A_{ij}=1}}\\
= & \Pi_{i}^{N}\int_{y_{i}\tilde{y}_{i}}\:e^{-i\tilde{y}_{i}y_{i}}\int_{x_{i}}e^{S_{0}(x_{i})+y_{i}y_{i}+i\tilde{y}_{i}x_{i}}\\
= & \left(\int_{y\tilde{y}}\,e^{-i\tilde{y}y+yy}\int_{x}e^{S_{0}(x)+y_{i}y_{i}+i\tilde{y}_{i}x_{i}}\right)^{N}\\
\overset{=}{?} & \int_{y\tilde{y}}\,\underbrace{e^{-Ni\tilde{y}y}\:e^{N\ln Z_{1}(y,\tilde{y})}}_{I(y,\tilde{y})}.
\end{align*}

\end_inset

In the last step, we have identified the 
\series bold
single-site partition function
\series default
 
\begin_inset Formula $Z_{1}$
\end_inset

, which apparently goes in as an ingredient to the overall partition function
 
\begin_inset Formula $\mathcal{Z}$
\end_inset

.
 The auxiliary field 
\begin_inset Formula $\tilde{y}$
\end_inset

 describes how those subsystems are coupled to one another.
\end_layout

\begin_layout Standard
So far, all manupulations were exact.
 Unfortunately, there is no Free Lunch, so that we now have to employ an
 approximation.
 This is called the 
\series bold
saddle point approximation
\series default
, and requires that the integrand is stationary,
\begin_inset Formula 
\begin{align*}
\partial_{y}I(y^{*},\tilde{y}^{*}) & =0\\
\partial_{\tilde{y}}I(y^{*},\tilde{y}^{*}) & =0.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Naively, this derives from the intuition that the integrand should be maximal.
 However, the integral in 
\begin_inset Formula $\tilde{y}$
\end_inset

 is complex, so what is the meaning of the variation with respect to 
\begin_inset Formula $\tilde{y}$
\end_inset

? Looking more closely, this is where the name 
\series bold
stationary phase approximation
\series default
 becomes more appropriate.
 Essentially, this picks out the value where the integrand oscillates most
 slowly, and its values don't average out.
 
\end_layout

\begin_layout Standard
In any case, this gives a set of 
\series bold
saddle point equations of the form
\begin_inset Formula 
\begin{align*}
\tilde{y}^{*} & =\frac{1}{Z_{1}(y,y^{*})}\int_{x}\frac{1}{2}y^{*}e^{S_{0}(x)+y^{*}y^{*}+i\tilde{y}^{*}x}=\frac{1}{2}y^{*}\langle1\rangle_{S_{1}}=\frac{1}{2}y^{*}.\\
y^{*} & =\frac{1}{Z_{1}(y,y^{*})}\int_{x}xe^{S_{0}(x)+y^{*}y^{*}+i\tilde{y}^{*}x}=\langle x\rangle_{S_{1}},
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where we defined 
\begin_inset Formula $S_{1}(x;y,\tilde{y})=S_{0}(x)+y^{*}y^{*}+i\tilde{y}^{*}x$
\end_inset

.
\end_layout

\begin_layout Standard
Note that curiously, 
\begin_inset Formula $y^{*}$
\end_inset

 is the average value of 
\begin_inset Formula $x$
\end_inset

 under this effective, one-dimensional theory 
\begin_inset Formula $S_{1}.$
\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
After this brief introduction, let's take a look how we can apply this to
 an actual physical problem.
 
\end_layout

\begin_layout Subsection*
Application to the Ising model
\end_layout

\begin_layout Standard
We can apply the developed formalism to the Ising model.
 It can be described again in terms of a partition function that depends
 on a parameter 
\begin_inset Formula $\bm{j}$
\end_inset

,
\begin_inset Formula 
\[
\mathcal{Z}(\bm{j})=\int_{\bm{x}}e^{-\bm{x}^{T}J\bm{x}+\bm{j}^{T}\bm{x}}.
\]

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "subsec:ising-ham"

\end_inset


\end_layout

\begin_layout Standard
'Here, the term 
\begin_inset Formula $\bm{x}^{T}J\bm{x}=x_{i}J_{ij}x_{j}$
\end_inset

 takes the role of the coupling 
\begin_inset Formula $A$
\end_inset

 between variables we have seen before.
 
\end_layout

\begin_layout Standard
To illustrate the main difficulty and how the mean-field approach can solve
 it, I will first discuss the ad-hoc approach that is typically introduced
 in undergraduate courses.
 Afterwards, we will see how this relates to the formal approach developed
 above.
\end_layout

\begin_layout Subsubsection*
Ad-hoc mean-field theory
\end_layout

\begin_layout Standard
The mean-field approach typically gets introduced in an ad-hoc fashion,
 in the sense that one replaces the value of each spin in the partition
 function by its average 
\begin_inset Formula $\bar{\bm{x}}$
\end_inset

 plus a small fluctuation 
\begin_inset Formula $\delta\bm{x}$
\end_inset

, merely amounting to a shift of integration variables.
 Subsequently, one discards quartic terms in 
\begin_inset Formula $\delta\bm{x}$
\end_inset

, so that we get
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathcal{Z}(j)=\int_{\bar{\bm{x}}+\delta\bm{x}}e^{-\bar{\bm{x}}^{T}J\bar{\bm{x}}-2\bar{\bm{x}}^{T}J(\bar{\bm{x}}+\delta\bm{x})+\bm{j}^{T}\left(\bar{\bm{x}}+\delta\bm{x}\right)}.
\]

\end_inset


\end_layout

\begin_layout Standard
This renders the partition function tractable, and we obtain the expectation
 by the self-consistency condition 
\begin_inset Formula 
\[
\bar{\bm{x}}\equiv\langle\bar{\bm{x}}+\delta\bm{x}\rangle_{\delta\bm{x}}=\partial_{\bm{j}}\ln\mathcal{Z}(\bm{j})|_{\bm{j}=0},
\]

\end_inset

yielding
\begin_inset Formula 
\begin{align*}
\bar{\bm{x}} & =\frac{1}{\mathcal{Z}(0)}\int_{\bar{\bm{x}}+\delta\bm{x}}e^{-2\bar{x}J(\bar{\bm{x}}+\delta\bm{x})}\\
 & =\tanh(-2J\bar{\bm{x}}).
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This exposes 
\begin_inset Formula $-2J\bar{\bm{x}}$
\end_inset

 as an 
\series bold
effective mean field
\series default
 that controls the statistics of 
\begin_inset Formula $\bar{\bm{x}}+\delta\bm{x}$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
A more formal approach
\end_layout

\begin_layout Standard
We can also solve the Ising model by the formal technique developed above.
 To this end, we again first decouple the action and then identify a field
 that influences all sites.
 
\end_layout

\begin_layout Standard
We start again from 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:ising-ham"
plural "false"
caps "false"
noprefix "false"

\end_inset


\begin_inset Formula 
\begin{align}
\mathcal{Z}(\bm{j}) & =\int_{\bm{x}}e^{-\bm{x}^{T}J\bm{x}+\bm{j}^{T}\bm{x}}\nonumber \\
 & \text{\textbf{decouple} via \ensuremath{\bm{y}:=J\bm{x}}}\nonumber \\
 & =\int_{\bm{y}\tilde{\bm{y}}}\:\int_{\bm{x}}e^{-\bm{x}^{T}\bm{y}-i\tilde{\bm{y}}^{T}(\bm{y}-J\bm{x})+\bm{j}^{T}\bm{x}}\nonumber \\
 & \text{\textbf{isolate} \ensuremath{\bm{x}}}\nonumber \\
 & =\int_{\bm{y}\tilde{\bm{y}}}e^{-i\tilde{\bm{y}}^{T}\bm{y}}\:\int_{\bm{x}}e^{-\bm{x}^{T}\bm{y}+i\tilde{\bm{y}}^{T}J\bm{x}+\bm{j}^{T}\bm{x}}.\label{eq:isolated-ising}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Unfortunately, we cannot yet decouple the later integrand, as 
\begin_inset Formula $J\bm{x}=J_{ij}x_{j}$
\end_inset

 does in general depend on 
\begin_inset Formula $i$
\end_inset

.
 To move forward, we have introduce one more feat: 
\end_layout

\begin_layout Subsubsection*
Averaging over the quenched disorder
\end_layout

\begin_layout Standard
If a problem is too hard, it makes sense to try solving an approximate version
 of this.
 In statistical physics, this usually means putting on coarse goggles, or
 
\series bold
ignoring microscopical details of the system
\series default
.
 Practically, this means that we say that we only know 
\begin_inset Formula $J$
\end_inset

 up to its statistics, and hence are interested in answers 
\series bold
on expectation
\series default
 over them.
 
\end_layout

\begin_layout Standard
It is common to assuming that its entries are identically, independently,
 and Gaussian distributed,
\begin_inset Formula 
\[
J_{ij}\sim\mathcal{N}\left(0,\,\sigma^{2}/N\right),
\]

\end_inset


\end_layout

\begin_layout Standard
an assumption that is backed partially by the central limit theorem and
 partially by reasons of analytical convenience.
 
\end_layout

\begin_layout Standard
With this, we get for the 
\begin_inset Formula $J$
\end_inset

-dependent term in 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:isolated-ising"
plural "false"
caps "false"
noprefix "false"

\end_inset

 by analytically solving a multivariate Gaussian integral
\begin_inset Formula 
\begin{align*}
 & \langle e^{i\tilde{\bm{y}}^{T}J\bm{x}}\rangle_{J_{ij}\sim\mathcal{N}(0,\sigma^{2}/N)}\\
= & \langle e^{i\tilde{\bm{y}}^{T}\bm{J}}\rangle_{J_{i}\sim\mathcal{N}(0,x_{i}^{2}\sigma^{2}/N)}\\
= & e^{-\frac{1}{2}\sigma^{2}/Nx_{i}^{2}\tilde{y}_{i}^{2}},
\end{align*}

\end_inset

which is called the 
\series bold
Hubbard trick
\series default
.
\end_layout

\begin_layout Standard
This finally allows us to decouple
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\langle\mathcal{Z}(\bm{j})\rangle_{J} & =\int_{\bm{y}\tilde{\bm{y}}}\,e^{-i\tilde{\bm{y}}^{T}\bm{y}}\:\int_{\bm{x}}e^{-\bm{x}^{T}\bm{y}+i\tilde{\bm{y}}^{T}J\bm{x}+\bm{j^{T}}\bm{x}}\\
 & =\int_{\bm{y}\tilde{\bm{y}}}\,e^{-i\tilde{\bm{y}}^{T}\bm{y}}\:\prod_{i}^{N}\int dx_{i}e^{-x_{i}y_{i}-\tilde{y}_{i}^{2}\sigma^{2}/Nx_{i}^{2}+j_{i}x_{i}}\\
 & \text{identify \ensuremath{Z_{1}}}\\
 & =\int_{y\tilde{y}}\,e^{-Ni\tilde{y}y}\:e^{N\ln Z_{1}(y,\tilde{y})}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Finally, we perform the saddle point approximation.
 After taking the derivative, we discard the subleading term 
\begin_inset Formula $\propto\sigma^{2}/N$
\end_inset

, and get
\begin_inset Formula 
\begin{align*}
\tilde{y}^{*} & =\frac{1}{Z_{1}(y^{*},\tilde{y}^{*})}\int_{x}\,-x\,e^{-xy^{*}+jx}=\langle-x\rangle_{S_{1}}\\
y^{*} & =\frac{1}{Z_{1}(y^{*},\tilde{y}^{*})}\int_{x}\,-2\tilde{y}\sigma^{2}/Nx^{2}\,e^{-xy^{*}+jx}\\
 & =\frac{1}{Z_{1}(y^{*},\tilde{y}^{*})}\int_{x}\,2\langle x\rangle_{S_{1}}\left(J\bm{x}\right)^{2}e^{-xy^{*}+jx}\\
 & =2\langle x\rangle_{S_{1}}\sigma^{2}/N\langle x^{2}\rangle_{S_{1}}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Recalling the introduction of 
\begin_inset Formula $\bm{y}$
\end_inset

 as 
\begin_inset Formula $\bm{y}=J\bm{x}$
\end_inset

, we can make sense of this
\begin_inset Formula 
\[
y_{i}=J_{ij}x_{j}=J_{ij}\left(J_{jk}x_{k}J_{jl}x_{l}\right)=\sigma^{2}x^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Equivalently, we can write the last equation as
\begin_inset Formula 
\[
y^{*}=\cosh^{-2}(\sigma^{2}y^{*}).
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Note that 
\begin_inset Formula $y^{*}$
\end_inset

 can be related to the mean-field 
\begin_inset Formula $\bar{x}$
\end_inset

 above in our ad-hoc approach, if we identify
\begin_inset Formula 
\[
\left(J\bar{x}\right)_{i}=N\sigma^{2}y^{*}.
\]

\end_inset


\end_layout

\begin_layout Plain Layout
This result is perhaps surprising, as a naive guess would have been
\begin_inset Formula 
\[
\langle|\left(Jx\right)_{i}|\rangle\approx\sqrt{\langle\left(Jx\right)_{i}^{2}\rangle}=\sqrt{\langle\sum_{kj}J_{ik}x_{k}J_{ij}x_{j}\rangle}\propto\sigma\sqrt{x\cdot x}\simeq\sigma\sqrt{N}.
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Plugging in this solution into the integral, we end up with
\begin_inset Formula 
\begin{align*}
\langle\mathcal{Z}(j)\rangle_{J,\,\text{MF}} & =\left(\int_{x}e^{-xy^{*}+jx}\right)^{N}\\
 & =\left(2\cosh\left(-y^{*}+j\right)\right)^{N}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
From this, we can see that 
\begin_inset Formula $y^{*}$
\end_inset

 naturally appears as a field influencing the statistics of 
\begin_inset Formula $x$
\end_inset

.
 In particular, we get
\begin_inset Formula 
\[
\bar{x}=\partial_{j}\ln\langle Z(j)\rangle_{J,\,\text{MF}}|_{j=0}=\tanh(-y^{*}).
\]

\end_inset


\end_layout

\begin_layout Subsection*
Advanced MFT cookbook
\end_layout

\begin_layout Standard
When tackling more complicated problems, there are a couple of identities
 that can take a large part of the way in decoupling an integral.
 These are
\end_layout

\begin_layout Subsubsection*
\begin_inset Formula $e^{-\frac{1}{2}y\sigma^{2}y}=\frac{1}{\left(2\pi\sigma^{2}\right)^{1/2}}\int_{\tilde{y}}e^{-\frac{1}{2}\frac{1}{\sigma^{2}}\tilde{y}^{2}+i\tilde{y}y}$
\end_inset

 decoupling (Hubbard-Stratonovich transform)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\langle e^{iy^{T}\tilde{y}}\rangle_{\tilde{y}\sim\mathcal{N}(0,\Sigma)}\coloneqq\frac{1}{\left(2\pi\det\Sigma\right)^{d/2}}\int d\tilde{y}\,e^{-\frac{1}{2}\tilde{y}^{T}\Sigma^{-1}\tilde{y}+iy^{T}\tilde{y}}\equiv e^{-\frac{1}{2}y^{T}\Sigma y}.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\langle e^{iy^{T}\tilde{y}}\rangle_{\tilde{y}\sim\mathcal{N}(0,\,\Sigma)}=e^{-\frac{1}{2}y^{T}\Sigma y}
\]

\end_inset


\end_layout

\begin_layout Standard
It is also useful to know that 
\begin_inset Formula 
\[
\langle e^{jx}\rangle=Z(j)=e^{W(j)},
\]

\end_inset


\end_layout

\begin_layout Standard
which for 
\begin_inset Formula $x$
\end_inset

 Gaussian gives
\begin_inset Formula 
\[
\langle e^{jx}\rangle=e^{\frac{1}{2}j\Sigma j},
\]

\end_inset


\end_layout

\begin_layout Standard
which is just Hubbard-Stratonovich from before!
\end_layout

\begin_layout Standard
This can be especially useful to get rid of the inverse 
\begin_inset Formula $A^{-1}$
\end_inset

 at the cost of introducing an integral.
 Note that this is just the Fourier transform of the input Gaussian.
 To remember the workings of this formula, note that the integrating exchanges
 
\begin_inset Formula $x$
\end_inset

 for 
\begin_inset Formula $y$
\end_inset

 in the Gaussian, removes the linearity and inverts the variance.
 
\end_layout

\begin_layout Standard
As a special case, we can take the denominator to the other side and get
 with 
\begin_inset Formula $A\rightarrow0$
\end_inset

 and get
\begin_inset Formula 
\[
\frac{\left(2\pi\right)^{d}}{\left(2\pi\det A\right)^{d/2}}e^{-\frac{1}{2}y^{T}A^{-1}y}\rightarrow\left(2\pi\right)^{d}\delta(y)=\int d\tilde{y}\,e^{iy^{T}\tilde{y}}.
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
\begin_inset Formula $\delta(y)=\int_{\tilde{y}}e^{i\tilde{y}y}$
\end_inset

 decoupling
\end_layout

\begin_layout Standard
This presents a more general and powerful technique.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
 & \int dx\,e^{S_{0}(x)+y(x)}\\
= & \int dx\int dy\,e^{S_{0}(x)+y}\,\delta(y-y(x))\\
= & \int dx\int dy\int d\tilde{y}\,e^{S_{0}(x)+i\tilde{y}(y-y(x))}\\
= & \int dy\int d\tilde{y}\,e^{i\tilde{y}y}C(\tilde{y})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Using this, it is for example possible to derive the Fourier transform of
 a Gaussian, defining a constraint 
\begin_inset Formula $y\overset{!}{=}y(x)=A^{-1}x$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
e^{-\frac{1}{2}x^{T}A^{-1}x} & =\int dy\,e^{-\frac{1}{2}y^{T}Ay}\,\delta(y-A^{-1}x)\\
 & =\int dyd\tilde{y}\,e^{-\frac{1}{2}y{}^{T}Ay+i\tilde{y}\left(y-A^{-1}x\right)}\\
 & =\int d\tilde{y}\,e^{-\frac{1}{2}\tilde{y}^{T}A^{-1}\tilde{y}-i\tilde{y}A^{-1}x}\\
\tilde{y}\rightarrow A\tilde{y}\: & =\int d\tilde{y}\,e^{-\frac{1}{2}\tilde{y}^{T}A\tilde{y}-i\tilde{y}x},
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where we did a transformation of variables in the last step.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
It is interesting to see how these two approaches relate: Any hard 
\begin_inset Formula $\delta$
\end_inset

-constraint may be implemented as a smooth 
\begin_inset Quotes eld
\end_inset

relaxation
\begin_inset Quotes erd
\end_inset

 via a Hubbard-Stratonovich transform:
\begin_inset Formula 
\begin{align*}
 & \int dx\int dy\,e^{S_{0}(x)+y(x)}\,\delta_{\sigma}(y-y(x))\\
= & \int dx\int dye^{-\frac{1}{2\sigma^{2}}(y-y(x))^{2}}\\
\overset{\text{H.S.}}{=} & \int dx\int dy\int d\tilde{y}e^{-\frac{1}{2}\sigma^{2}\tilde{y}^{2}+i\tilde{y}(y-y(x))}\\
= & \int dy\int d\tilde{y}e^{-\frac{1}{2}\sigma^{2}\tilde{y}^{2}+i\tilde{y}y}\,C(\tilde{y}).
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The first term becomes approximately constant as we take the limit 
\begin_inset Formula $\sigma\rightarrow0$
\end_inset

, approximating the 
\begin_inset Formula $\delta$
\end_inset

-function.
\end_layout

\begin_layout Subsubsection*
Lagrange multipliers as realizable constraints
\begin_inset CommandInset label
LatexCommand label
name "subsec:Lagrange-multipliers-delta-gauss"

\end_inset


\end_layout

\begin_layout Standard
Suppose we strive to optimize a function 
\begin_inset Formula $\mathcal{L}(x)$
\end_inset

 under a constraint 
\begin_inset Formula $g(x)=0$
\end_inset

.
 The method of Lagrange multipliers prescribes to introduce dummy parameter
 
\begin_inset Formula $\tilde{y}$
\end_inset

.
 Then, an auxiliary objective is to be minimized
\begin_inset Formula 
\[
\tilde{\mathcal{L}}(x;\tilde{y})=\mathcal{L}(x)+\tilde{y}y(x)
\]

\end_inset


\end_layout

\begin_layout Standard
via requiring 
\begin_inset Formula $\partial_{x}\tilde{\mathcal{L}}(x^{\star};\tilde{y}^{\star})=0$
\end_inset

 and 
\begin_inset Formula $\partial_{\tilde{y}}\tilde{\mathcal{L}}(x^{\star};\tilde{y}^{\star})=0$
\end_inset

.
 Then, the constraint is satisfied by construction.
 There is however a caveat that we will dig into below.
 
\end_layout

\begin_layout Standard
How does this relate to our former method? Let us rewrite the objective
 as an integral by superimposing all possible solutions.
 
\begin_inset Formula 
\[
\int dx\,e^{-\mathcal{L}(x)}\,\delta(y(x)-0).
\]

\end_inset


\end_layout

\begin_layout Standard
We would like to find the 
\begin_inset Formula $x$
\end_inset

 that maximizes the integrand.
 It will become clear in a moment while it is useful to exponentiate the
 loss.
 To this end, let's again raise the 
\begin_inset Formula $\delta$
\end_inset

-constraint via our newly learned trick:
\begin_inset Formula 
\[
\int dx\int d\tilde{y}\,e^{-\mathcal{L}(x)+i\tilde{y}\left(y(x)-0\right)}\eqqcolon\int dx\int d\tilde{y}\,e^{-\tilde{\mathcal{L}}(x)}
\]

\end_inset


\end_layout

\begin_layout Standard
At this point, we can look for the point that maximizes the integrand.
 This leads to saddle-point equations
\begin_inset Formula 
\begin{align*}
\partial_{x}\tilde{\mathcal{L}}(x^{\star};\tilde{y}^{\star}) & =0\\
\partial_{\tilde{y}}\tilde{\mathcal{L}}(x^{\star};\tilde{y}^{\star}) & =0.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This is precisely the prescription of the Lagrange paradigm! The Lagrange
 multiplier can hence be thought of as an auxiliary field in disguise that
 penalizes the objective's values to comply with the constraint.
 Crucially however, we generally have no guarantee that the saddle point
 equations have a solution.
\end_layout

\begin_layout Standard
This perhaps also reveals that an optimization via Lagrange multipliers
 may not have a solution.
 What to do then? We could employ a 
\begin_inset Formula $\delta_{\sigma}$
\end_inset

-relaxation, which will ensure that an optimum exists.
 This allows for slightly (
\begin_inset Formula $\sigma$
\end_inset

) violating the constraint until a minimum exists.
 
\end_layout

\end_body
\end_document
